# Oscar
Scripts for to inference using Oscar in Image Captioning and VQA tasks

## Requirements
```
For inference One Image
Minimum VRAM = 6GB, You must run 'torch.cuda.empty_cache()' to flush gpu cache at every inference
Recommemd VRAM = 7GB or more
```

## Demo
```
To Know How to use Oscar models see *.ipynb
```
