# Oscar
Scripts for to inference using Oscar in Image Captioning and VQA tasks.

## Requirements
```
For inference One Image
Minimum VRAM = 6GB, You must run 'torch.cuda.empty_cache()' to flush gpu cache at every inference
Recommemd VRAM = 7GB or more
```

## Demo
```
To Know How Oscar+ model which use VinVL as Encoder inferencex, See vinvl.ipynb .

The Demo which inference using bottom up attention will be added soon.

```
