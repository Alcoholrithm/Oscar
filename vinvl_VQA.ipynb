{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "from encoder.vinvl_encoder import Encoder\n",
    "from decoder.vqa_decoder import Decoder\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder = Encoder()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "decoder = Decoder(checkpoint = '/workspace/shared/pretrained/vqa/large/best', device='cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img1 = cv2.imread('/workspace/pitching.jpg', cv2.IMREAD_UNCHANGED)\n",
    "img2 = cv2.imread('/workspace/airplane.jpg', cv2.IMREAD_UNCHANGED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(20,12))\n",
    "for i in range(1,3):\n",
    "    fig.add_subplot(fig.add_subplot(1, 2, i))\n",
    "    plt.imshow(cv2.cvtColor(eval('img' + str(i)), cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoded = encoder([img1, img2])\n",
    "questions = [\"What color is the uniform\", \"How about weather\"]\n",
    "for i in range(len(encoded)):\n",
    "    encoded[i].append(questions[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out = decoder(encoded)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_answer(candidates):\n",
    "    outs = []\n",
    "    for temp in candidates:\n",
    "        arr = []\n",
    "        for value in temp.values():\n",
    "            arr.append(value)\n",
    "        arr = torch.nn.functional.softmax(torch.Tensor(arr), dim=0)\n",
    "        argmax = arr.argmax().numpy().item()\n",
    "        if arr[argmax].numpy().item() / arr.sum() > 0.9:\n",
    "            outs.append([list(temp.keys())[argmax], arr[argmax].item()])\n",
    "        else:\n",
    "            outs.append(\"Unkwonw\")\n",
    "    return outs\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_answer(out)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('oscar': conda)"
  },
  "interpreter": {
   "hash": "74e4a35787308bc889be406a76744471ca2617d3fd471f93d287c951dbf5286c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}